---
title: "TC Genesis Bayesian Analysis"
author: "Keith Howen"
date: "2025-03-10"
output: pdf_document
---

## Working Directory Setup using `here()`
Use `here()` to *standardize the working directory between R markdown and
R console* as opposed to using `getwd()` (and `setwd()`), at the slight
inconveniences of importing the `here` library, using `here()` to write file
paths, and manually specify paths for files outside the working directory.

```{r setup, include=FALSE}
#install.packages('here')
library(here)
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
here()
```



## R Markdown tips (delete later)

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
#summary(cars)
```


You can also embed plots, for example:

```{r pressure, echo=FALSE}
#plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.


## Importing the data

```{r}

# equivalent to read.csv("../data/data_path)
data_path = "envDataset_12h_10x10_with_mask.csv"
data = read.csv(here("..", "data", data_path))

```




## Data Preprocessing




### Preview

```{r}
data
```

### Inspect data types

```{r}
# for each of column indices i in 1,..,150, 
# map it to the data type of i-th column in data
sapply(1:ncol(data), function(i){typeof(data[,i])})
```

The only categorical data type is the `basin` variable, and the last column 
correspond to the response variable, which is binary.

### Missing data detected.

```{r}

num.na.per.column = data.frame(
    colnames(data),
    sapply(1:ncol(data), function(i){sum(is.na(data[,i])) } )
)

num.na.per.column[
  order(num.na.per.column[,2], decreasing=TRUE), ]


```

Only the `basin` column. 

#### Or is it?

```{r}
table(data[,1])
```
Based on the given research paper,

Western North pacific = WP
Eastern North Pacific = EP
South Pacific = SP
North Atlantic = ?
South Atlantic = SA
North Indian Ocean = NI
South Indian Ocean = SI

Which means North Atlantic is NA but somehow it is interpreted as missing data.

```{r}
data[is.na(data[,1]),  ]
```

#### Apply changes.

```{r}
# cat means category
data[,1] = sapply(data[,1], function(cat){if(is.na(cat)){"NA"}else{cat}})
```

Verify that there is no missing data, and "NA" is correctly encoded as "NA"
(i.e. North Atlantic basin)

```{r}
sum(is.na(data))
unique(data[,1])
```


### Encode categorical variables.

#### Apply changes.

I used the `model.matrix` function which is originally for creating design
matrices.

```{r}
data.encoded = cbind(data, model.matrix(~ 0 + basin, data = data))
```


```{r}
subset(data.encoded, select = -c(basin))
```




## Function to do it all (for modularizing)

```{r}

# Preprocess the tropical cyclone dataset for model training.
# 
# @param dta = the raw data frame from the envData dataset.
#
# @returns a list of 2 elements: the preprocessed data excluding the response, and
# the response

preprocess = function(dta){
  
  # encode missing data from 'basin' as an actual category
  #dta$basin = sapply(dta$basin, function(cat){if(is.na(cat)){"NA"}else{cat}})
  dta$basin[is.na(dta$basin)] = "NA" # better readability and efficiency
  
  # might be a good idea to keep basin as a factor for modelling purposes!
  dta$basin = as.factor(dta$basin)
  
  # encode categories in 'basin' using one hot encoding
  dta.encoded = cbind(dta, model.matrix(~ 0 + basin, data = dta))
  
  # get data frame of predictors only: we can remove the original 'basin' column
  dta.predictors = subset(dta.encoded, select = -c(basin, TC_genesis))
  
  # get data frame of the response only
  dta.response = dta.encoded$TC_genesis
  
  return(list(predictors = dta.predictors,
              response = dta.response))
}

```

### Re-eimporting the data from scratch

```{r}
# equivalent to read.csv("../data/data_path)
data_path = "envDataset_12h_10x10_with_mask.csv"
data = read.csv(here("..", "data", data_path))
```

### Validating the function output

```{r}
preprocess.test = preprocess(data)
```

Check data types of predictors -- make sure they are numeric

```{r}
unique(apply(preprocess.test$predictors,MARGIN=2, typeof))
```

Check distribution of response to ensure that we haven't done anything weird
about it

```{r}
table(preprocess.test$response)
```






